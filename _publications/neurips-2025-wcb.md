---
title: "Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally"
collection: cations
category: conferences
permalink: /publication/2025-wcb
excerpt: "Introduces the World Central Banks (WCB) dataset, the largest multilingual corpus of monetary policy communications, with expert-annotated stance, temporal, and uncertainty labels. Benchmarks show cross-bank training improves classification and interpretability."
date: 2025-12-02
venue: "NeurIPS"
paperurl: "https://gcb-web-bb21b.web.app/static/pdf/main.pdf"
slidesurl: ""
posterurl: "https://gcb-web-bb21b.web.app/static/poster.pdf"
codeurl: "https://github.com/gtfintechlab/WorldCentralBanks"
website: "https://gcb-web-bb21b.web.app/"
dataseturl: "https://huggingface.co/collections/gtfintechlab/wcb-678965e38178c63158b45fdf"
citation: 'Agam Shah*, Siddhant Sukhani*, Huzaifa Pardawala*, Saketh Budideti†, Riya Bhadani†, Rudra Gopal†, Siddhartha Somani†, Michael Galarnyk†, <b>Soungmin Lee†</b>. (2025). "Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally." <i>NeurIPS 2025</i>.'
---

The **World Central Banks (WCB)** paper introduces the most comprehensive dataset of central bank communications to date, spanning **380k+ sentences from 25 central banks across 28 years**.
It includes expert-annotated labels for **stance detection** (hawkish/dovish/neutral), **temporal classification**, and **uncertainty estimation**, designed to evaluate both pretrained and large language models in high-stakes financial policy contexts.

Key highlights:

- Benchmarked **15k+ experiments** across state-of-the-art NLP models, including large language models.
- Demonstrated that **cross-bank training** yields significantly better performance than single-bank training.
- Released the **WCB dataset**, along with scripts and evaluation pipelines, to support further research on monetary policy and financial NLP.

† Indicates **core contributor**.
